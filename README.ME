# AnÃ¡lise ExploratÃ³ria do Programa PIPE e Modelagem de Dados

Este repositÃ³rio contÃ©m a soluÃ§Ã£o para o Desafio TÃ©cnico do Processo Seletivo de EstÃ¡gio em AnÃ¡lise de Dados do **Supera Parque**. O projeto consiste na extraÃ§Ã£o, tratamento e visualizaÃ§Ã£o de dados pÃºblicos da FAPESP, alÃ©m da modelagem de um banco de dados relacional.

## ğŸ“‹ Sobre o Projeto

O objetivo foi analisar os auxÃ­lios concedidos pelo programa **"Pesquisa Inovativa em Pequenas Empresas (PIPE)"** da FAPESP e projetar um sistema para gestÃ£o de pesquisa.

O desafio foi dividido em duas etapas:
1.  **Case 1 (Engenharia de Dados & BI):** Web Scraping da biblioteca virtual da FAPESP, limpeza de dados (ETL) e criaÃ§Ã£o de dashboards analÃ­ticos.
2.  **Case 2 (Banco de Dados):** Modelagem de dados (MER/DER) e desenvolvimento de consultas SQL para extraÃ§Ã£o de insights.

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.14.0**: Linguagem principal para automaÃ§Ã£o.
* **Bibliotecas Python**:
    * `requests`: RequisiÃ§Ãµes HTTP.
    * `BeautifulSoup (bs4)`: Web Scraping e parsing de HTML.
    * `pandas`: ManipulaÃ§Ã£o, limpeza e anÃ¡lise de dados.
    * `openpyxl`: ExportaÃ§Ã£o para Excel.
    * `re`: ExpressÃµes Regulares (Regex) para tratamento de texto avanÃ§ado.
* **Power BI**: VisualizaÃ§Ã£o de dados e dashboards interativos.
* **SQL**: Consultas estruturadas para banco de dados.
* **brModelo**: CriaÃ§Ã£o de Diagramas Entidade-Relacionamento (DER).

## ğŸ“‚ Estrutura do RepositÃ³rio

```text
â”œâ”€â”€ ExtraÃ§Ã£o de dados (Case1).py       # Script de Web Scraping e paginaÃ§Ã£o
â”œâ”€â”€ Limpeza dos dados (Case 1).py      # Script de ETL (tratamento e padronizaÃ§Ã£o)
â”œâ”€â”€ requirements.txt                   # Lista de dependÃªncias do projeto
â”œâ”€â”€ dados_limpos_case1.xlsx            # Base de dados final tratada (Output)
â”œâ”€â”€ Case1_Dashboard_Analise.pbix       # Arquivo fonte do Dashboard (Power BI)
â”œâ”€â”€ Case2_Diagrama_DER.png             # Imagem do Modelo Entidade-Relacionamento
â”œâ”€â”€ Case2_Consultas_SQL.txt            # Scripts das queries solicitadas
â”œâ”€â”€ Apresentacao_Executiva.pdf         # ApresentaÃ§Ã£o final com resultados e insights
â””â”€â”€ README.md                          # DocumentaÃ§Ã£o do projeto

## ğŸš€ Como Executar o Projeto

**PrÃ©-requisitos:**
Certifique-se de ter o Python instalado.

1. Clone o repositÃ³rio:
    ```bash
     git clone [https://github.com/Tamires-Bassi/Analise-exploratoria-e-visualizacao-do-programa-PIPE-Data-Science-BI-](https://github.com/Tamires-Bassi/Analise-exploratoria-e-visualizacao-do-programa-PIPE-Data-Science-BI-)
     cd Analise-exploratoria-e-visualizacao-do-programa-PIPE-Data-Science-BI-
    ```

2. Instale as dependÃªncias:
    ```bash
    pip install -r requirements.txt
    ```
3. Execute a Coleta de Dados: O script irÃ¡ percorrer as pÃ¡ginas da Biblioteca Virtual da FAPESP e gerar um arquivo bruto.
```bash
    python "ExtraÃ§Ã£o de dados (Case1).py"
    ```

4. Execute a Limpeza de Dados: Este passo processa o arquivo bruto e gera o arquivo dados_limpos_case1.xlsx.
    ```bash
    python "Limpeza dos dados (Case 1).py"
    ```

## ğŸ“Š Destaques da AnÃ¡lise (Case 1)
O processo de ETL permitiu estruturar dados nÃ£o padronizados, resultando em:

* **NormalizaÃ§Ã£o GeogrÃ¡fica:** SeparaÃ§Ã£o precisa de Cidades e Estados para criaÃ§Ã£o de mapas.

* **Tratamento Temporal:** ConversÃ£o de textos de vigÃªncia para datas estruturadas, permitindo anÃ¡lise de evoluÃ§Ã£o temporal.

* **Filtros EstratÃ©gicos:** IdentificaÃ§Ã£o de projetos especÃ­ficos em polos tecnolÃ³gicos como RibeirÃ£o Preto.

## ğŸ—„ï¸ Modelagem de Dados (Case 2)
A soluÃ§Ã£o para o segundo case envolve a estruturaÃ§Ã£o de um banco de dados normalizado para gestÃ£o de projetos de pesquisa.

* **Entidades Principais:** Pesquisador, InstituiÃ§Ã£o, Projeto, AuxÃ­lio.

* **Destaque:** ImplementaÃ§Ã£o de tabela associativa (Projeto_Pesquisador) para resoluÃ§Ã£o de relacionamento N:N (Muitos-para-Muitos).

* **Consultas SQL:** Desenvolvimento de queries complexas utilizando JOIN, GROUP BY e HAVING para relatÃ³rios gerenciais.

Detalhes do diagrama (DER) e os cÃ³digos SQL completos podem ser visualizados nos arquivos Case2_Diagrama_DER.png e Case2_Consultas_SQL.txt.

## ğŸ¤– Uso de InteligÃªncia Artificial
Conforme diretrizes do processo seletivo, houve o uso transparente de ferramentas de IA (Gemini) para:

* DepuraÃ§Ã£o de erros de conexÃ£o HTTP durante o scraping.

* RevisÃ£o de sintaxe e boas prÃ¡ticas (aliases) nas consultas SQL.

* Toda a lÃ³gica de negÃ³cio, validaÃ§Ã£o dos dados e construÃ§Ã£o dos scripts foi realizada pela autora.

## ğŸ‘©â€ğŸ’» Autora
Tamires de Sousa Bassi